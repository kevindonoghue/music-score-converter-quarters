{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wExCys3UqAZh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9WkcvxtrM9F"
   },
   "outputs": [],
   "source": [
    "image_data = np.load('storage/partial_image_data_160_240.npy')\n",
    "with open('storage/partial_extra_data_160_240.json') as f:\n",
    "    extra_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pitch', 'note', '-1', '0', '3', '<END>', '12', 'staff', 'mp', 'F', '16', 'whole', '1', 'backup', '7', 'type', 'chord', 'dot', 'half', 'B', 'quarter', 'G', 'p', 'C', 'rest', '2', 'measure', 'mf', '<START>', 'D', '5', '}', 'eighth', '8', 'E', '4', '16th', '6', 'slur', 'f', 'duration', 'ff', 'pp', 'A', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "lexicon = list(set([x for y in extra_data for x in y['pc']]))\n",
    "lexicon = lexicon + ['<PAD>']\n",
    "print(lexicon)\n",
    "word_to_ix = {word: ix for ix, word in enumerate(lexicon)}\n",
    "ix_to_word = {ix: word for ix, word in enumerate(lexicon)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4D-RYfz0zKqt"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "seq_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8800, 1, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "# augment image data to include key and time signature info\n",
    "aug = []\n",
    "for i in range(len(extra_data)):\n",
    "    measure_length = extra_data[i]['measure_length']\n",
    "    key_number = extra_data[i]['key_number']\n",
    "    key_number += 7\n",
    "    vec = np.zeros((2, 20))\n",
    "    vec[0, key_number] += 1\n",
    "    if measure_length == 12:\n",
    "        vec[1, 0] += 1\n",
    "    elif measure_length == 16:\n",
    "        vec[1, 1] += 1\n",
    "    tiled = np.tile(vec, (80, 12))\n",
    "    aug.append(tiled)\n",
    "aug = np.array(aug)\n",
    "aug = aug.reshape(-1, 1, 160, 240)\n",
    "print(aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RzCifP7zg9S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8800, 2, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "language_data = dict()\n",
    "\n",
    "language_samples = []\n",
    "image_indices = []\n",
    "for image_index, datum in enumerate(extra_data):\n",
    "    pc = ['<PAD>'] *seq_len + datum['pc'] + ['<PAD>']*seq_len\n",
    "    for i in range(len(pc)-seq_len-1):\n",
    "        seq = np.array([word_to_ix[word] for word in pc[i:i+seq_len]])\n",
    "        target_seq = np.array([word_to_ix[word] for word in pc[i+1:i+seq_len+1]])\n",
    "        language_samples.append(np.array([seq, target_seq]))\n",
    "        image_indices.append(image_index)\n",
    "\n",
    "language_samples = np.array(language_samples)\n",
    "image_indices = np.array(image_indices)\n",
    "language_data[seq_len] = (language_samples, image_indices)\n",
    "    \n",
    "image_data = image_data.reshape(-1, 1, 160, 240)\n",
    "image_data = np.concatenate([image_data, aug], axis=1)\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXyPoNnMeANi"
   },
   "outputs": [],
   "source": [
    "epoch_lengths = dict()\n",
    "epoch_lengths[seq_len] = int(language_data[seq_len][0].shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkgZyeXf21qr"
   },
   "outputs": [],
   "source": [
    "class ConvUnit(nn.Module):\n",
    "    def __init__(self, input_size, output_size, filter_size, stride, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size, output_size, filter_size, stride=1, padding=padding)\n",
    "        self.dp1 = nn.Dropout2d(p=dropout)\n",
    "        self.bn1 = nn.BatchNorm2d(output_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(output_size, output_size, filter_size, stride=stride, padding=padding)\n",
    "        self.dp2 = nn.Dropout2d(p=dropout)\n",
    "        self.bn2 = nn.BatchNorm2d(output_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.dp1(self.conv1(x))))\n",
    "        x = self.relu2(self.bn2(self.dp2(self.conv2(x))))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(ConvUnit(2, 64, 3, 2, 1, 0.25), # (160, 240) --> (80, 120)\n",
    "                                 ConvUnit(64, 128, 3, 2, 1, 0.25), # (80, 120) --> (40, 60)\n",
    "                                 ConvUnit(128, 128, 3, 4, 1, 0.25), # (40, 60) --> (10, 15)\n",
    "                                 ConvUnit(128, 128, 3, 5, 1, 0.25)) # (10, 15) --> (2, 3)\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "        self.embed = nn.Embedding(num_embeddings=len(lexicon), embedding_dim=5)\n",
    "        self.lstm1 = nn.LSTM(input_size=5, hidden_size=256, num_layers=2, batch_first=True, dropout=0.25)\n",
    "        self.lstm2 = nn.LSTM(input_size=256+256, hidden_size=256, num_layers=2, batch_first=True, dropout=0.25)\n",
    "        self.fc2 = nn.Linear(256, len(lexicon))\n",
    "        \n",
    "    def forward(self, image_input, language_input, internal1=None, internal2=None):\n",
    "        bs = image_input.shape[0]\n",
    "        seq_len = language_input.shape[1]\n",
    "        if internal1:\n",
    "            h1, c1 = internal1\n",
    "        else:\n",
    "            h1 = torch.zeros(2, bs, 256).cuda()\n",
    "            c1 = torch.zeros(2, bs, 256).cuda()\n",
    "        if internal2:\n",
    "            h2, c2 = internal2\n",
    "        else:\n",
    "            h2 = torch.zeros(2, bs, 256).cuda()\n",
    "            c2 = torch.zeros(2, bs, 256).cuda()\n",
    "        image_output = self.fc1(self.cnn(image_input).view(bs, 768))\n",
    "        image_output = image_output.repeat(1, seq_len).view(bs, seq_len, 256)\n",
    "        language_output, (h1, c1) = self.lstm1(self.embed(language_input), (h1, c1))\n",
    "        concatenated = torch.cat([image_output, language_output], 2)\n",
    "        lstm2_out, (h2, c2) = self.lstm2(concatenated, (h2, c2))\n",
    "        out = self.fc2(lstm2_out)\n",
    "        return out, (h1, c1), (h2, c2)\n",
    "    \n",
    "    def fit(self, image_data, language_data, optimizer, loss_fn, num_iterations, seq_len, rate_decay):\n",
    "        t = time.time()\n",
    "        for i in range(num_iterations):\n",
    "            self.train()\n",
    "            X = language_data[0][:, 0, :]\n",
    "            y = language_data[0][:, 1, :]\n",
    "            image_indices = language_data[1]\n",
    "            batch_indices = np.random.choice(X.shape[0], size=batch_size)\n",
    "            x = torch.Tensor(X[batch_indices]).type(torch.long).cuda()\n",
    "            targets = torch.Tensor(y[batch_indices]).type(torch.long).cuda()\n",
    "            image_batch = torch.Tensor(image_data[image_indices[batch_indices]]).type(torch.float).cuda()\n",
    "            out, _, _ = self.forward(image_batch, x)\n",
    "            out = out.view(batch_size*seq_len, len(lexicon))\n",
    "            targets = targets.view(batch_size*seq_len)\n",
    "            loss = loss_fn(out, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                n = np.random.choice(image_data.shape[0])\n",
    "                prediction = self.predict(image_data[n])\n",
    "                print(f'iteration: {i}, loss: {loss}, seconds elapsed: {time.time() - t}')\n",
    "                print('predicted : ' + prediction)\n",
    "                print('true      : ' + ' '.join(dsl_data[n]))\n",
    "                print('---------------------------')\n",
    "                with open('measure_model_quarters_log_file-2019-09-19.txt', 'a+') as f:\n",
    "                    f.write(f'iteration: {i}, loss: {loss}, seconds elapsed: {time.time()-t}\\n')\n",
    "                    f.write('predicted :  ' + prediction + '\\n')\n",
    "                    f.write('true      :  ' + ' '.join(dsl_data[n]) + '\\n')\n",
    "                    f.write('------------------------------\\n')\n",
    "                    \n",
    "            if i % 5000 == 0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= rate_decay\n",
    "                torch.save(model, f'measure_model_quarters_iteration_{i}_2019-09-19.pt')\n",
    "\n",
    "                \n",
    "             \n",
    "    def predict(self, image):\n",
    "        self.eval()    \n",
    "        with torch.no_grad():\n",
    "            image = torch.Tensor(image).type(torch.float).view(1, 2, 160, 240).cuda()\n",
    "            output_sequence = ['<START>']\n",
    "            h1 = torch.zeros(2, 1, 256).cuda()\n",
    "            c1 = torch.zeros(2, 1, 256).cuda()\n",
    "            h2 = torch.zeros(2, 1, 256).cuda()\n",
    "            c2 = torch.zeros(2, 1, 256).cuda()\n",
    "            while output_sequence[-1] != '<END>' and len(output_sequence)<300:\n",
    "                language_input = torch.Tensor([word_to_ix[output_sequence[-1]]]).type(torch.long).view(1, 1).cuda()\n",
    "                out, (h1, c1), (h2, c2) = self.forward(image, language_input, (h1, c1), (h2, c2))\n",
    "                _, language_input = out[0, 0, :].max(0)\n",
    "                output_sequence.append(ix_to_word[language_input.item()])\n",
    "        self.train()\n",
    "        return ' '.join(output_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6Hbs3vSF2ub"
   },
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B4fB_4TqJtCr",
    "outputId": "41f1888f-3401-461f-d4e8-ff82c0eb765b"
   },
   "outputs": [],
   "source": [
    "model.fit(image_data, language_data[seq_len], optimizer, loss_fn, 40000, seq_len, 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('pix2code-2019-09-15.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kQTOxe0f96VM",
    "outputId": "6a97253b-ba4e-4c20-fcc9-edb6782c12d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 64, 256)\n"
     ]
    }
   ],
   "source": [
    "# image_test_data = np.load('generated_test_data/resized_test_images.npy')\n",
    "# print(image_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "5Ql3C6RECn1t",
    "outputId": "9f67decb-ba0d-4a8e-9f37-71e0a62dcd1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attributes', '{', 'divisions', '{', '1', '}', 'key', '{', '3', '}', 'time', '{', '4', ',', '4', '}', 'clef', '{', 'G', ',', '2', '}', '}', 'note', '{', 'C', ',', '-1', ',', '5', ',', '1', '}', 'note', '{', 'E', ',', '-1', ',', '5', ',', '1', '}', 'note', '{', 'G', ',', '0', ',', '4', ',', '1', '}', 'note', '{', 'E', ',', '1', ',', '5', ',', '1', '}']\n"
     ]
    }
   ],
   "source": [
    "# test_dsl0 = model.predict(image_test_data[0])[8:-6].split()\n",
    "# print(test_dsl0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3Ic2mbxCCtOy",
    "outputId": "2fc6d61d-b89c-4d49-d596-47af07b49104"
   },
   "outputs": [],
   "source": [
    "# from dsl_to_xml import dsl_to_xml\n",
    "# from bs4 import BeautifulSoup\n",
    "# soup0 = dsl_to_xml(test_dsl0)\n",
    "# print(soup0.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7N1JLsTMDk3k"
   },
   "outputs": [],
   "source": [
    "# for i in range(500):\n",
    "#     pred_dsl = model.predict(image_test_data[i]).split()[1:-1]\n",
    "#     pred_soup = dsl_to_xml(pred_dsl)\n",
    "#     with open(f'test_predictions/{i}.musicxml', 'w+') as f:\n",
    "#         f.write(str(pred_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFjEK8oSEPDc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "single_measure_pix2code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
