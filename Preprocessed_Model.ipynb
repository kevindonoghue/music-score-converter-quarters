{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessed Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1ZP7tpDT5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "288faf79-8f0b-4261-ccc5-d778cc2b7bbc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FtDx-BtDDFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import time\n",
        "\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CM9iZrqDMue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/measure_model_quarters')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7qVsZW8DpM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = np.load('preprocessed/quarter_measure_data_images_preprocessed.npy')\n",
        "subsequences = np.load('preprocessed/quarter_measure_data_subsequences.npy')\n",
        "image_indices = np.load('preprocessed/quarter_measure_data_subsequence_image_indices.npy')\n",
        "measure_data_channels = np.load('preprocessed/quarter_measure_data_time_and_key_tiles.npy')\n",
        "with open('preprocessed/other_data.json') as f:\n",
        "    other_data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLipZCGsEZ2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_ix = other_data['lexicon']['word_to_ix']\n",
        "ix_to_word = other_data['lexicon']['ix_to_word']\n",
        "len_lexicon = len(list(word_to_ix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRWtTdX-PVAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "seq_len = 64\n",
        "lstm_hidden_size = 5\n",
        "fc1_output_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5de2pYklERQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvSubunit(nn.Module):\n",
        "    def __init__(self, input_size, output_size, filter_size, stride, padding, dropout):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(input_size, output_size, filter_size, stride=stride, padding=padding)\n",
        "        self.dp = nn.Dropout2d(p=dropout)\n",
        "        self.bn = nn.BatchNorm2d(output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sequential = nn.Sequential(self.conv, self.dp, self.bn, self.relu)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sequential(x)\n",
        "\n",
        "class ConvUnit(nn.Module):\n",
        "    def __init__(self, input_size, output_size, filter_size, stride, padding, dropout):\n",
        "        super().__init__()\n",
        "        self.subunit1 = ConvSubunit(input_size, output_size, filter_size, stride, padding, dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.subunit1(x)\n",
        "        return x\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, len_lexicon, lstm_hidden_size, fc1_output_size, device):\n",
        "        super().__init__()\n",
        "        self.len_lexicon = len_lexicon\n",
        "        self.lstm_hidden_size = lstm_hidden_size\n",
        "        self.fc1_output_size = fc1_output_size\n",
        "        self.num_iterations = 0\n",
        "        self.train_time = 0\n",
        "        self.cnn = nn.Sequential(ConvUnit(2, 64, 3, 2, 1, 0.25), # (200, 200) --> (100, 100)\n",
        "                                 ConvUnit(64, 128, 3, 2, 1, 0.25), # (100, 100) --> (50, 50)\n",
        "                                 ConvUnit(128, 128, 3, 5, 1, 0.25), # (50, 50) --> (10, 10)\n",
        "                                 ConvUnit(128, 128, 3, 5, 1, 0.25)) # (10, 10) --> (2, 2)\n",
        "        self.fc1 = nn.Linear(512, self.fc1_output_size)\n",
        "        self.embed = nn.Embedding(num_embeddings=self.len_lexicon, embedding_dim=5)\n",
        "        self.lstm1 = nn.LSTM(input_size=5, hidden_size=self.lstm_hidden_size, num_layers=2, batch_first=True, dropout=0.25)\n",
        "        self.lstm2 = nn.LSTM(input_size=self.fc1_output_size+self.lstm_hidden_size, hidden_size=self.lstm_hidden_size, num_layers=2, batch_first=True, dropout=0.25)\n",
        "        self.fc2 = nn.Linear(self.lstm_hidden_size, self.len_lexicon)\n",
        "        \n",
        "    def forward(self, image_input, language_input, internal1=None, internal2=None):\n",
        "        bs = image_input.shape[0]\n",
        "        sl = language_input.shape[1]\n",
        "        if internal1:\n",
        "            h1, c1 = internal1\n",
        "        else:\n",
        "            h1 = torch.zeros(2, bs, self.lstm_hidden_size).to(device)\n",
        "            c1 = torch.zeros(2, bs, self.lstm_hidden_size).to(device)\n",
        "        if internal2:\n",
        "            h2, c2 = internal2\n",
        "        else:\n",
        "            h2 = torch.zeros(2, bs, self.lstm_hidden_size).to(device)\n",
        "            c2 = torch.zeros(2, bs, self.lstm_hidden_size).to(device)\n",
        "        image_output = self.fc1(self.cnn(image_input).view(bs, 512))\n",
        "        image_output = image_output.repeat(1, sl).view(bs, sl, self.fc1_output_size)\n",
        "        language_output, (h1, c1) = self.lstm1(self.embed(language_input), (h1, c1))\n",
        "        concatenated = torch.cat([image_output, language_output], 2)\n",
        "        lstm2_out, (h2, c2) = self.lstm2(concatenated, (h2, c2))\n",
        "        out = self.fc2(lstm2_out)\n",
        "        return out, (h1, c1), (h2, c2)\n",
        "    \n",
        "    def fit(self, total_iterations, optimizer, loss_fn, rate_decay, print_every=100):\n",
        "        train_start_time = time.time()\n",
        "        for i in range(total_iterations):\n",
        "            batch_indices = np.random.choice(len(subsequences), size=batch_size)\n",
        "            image_batch = images[image_indices[batch_indices]].reshape(-1, 1, 200, 200)/255\n",
        "            measure_data_channel_batch = measure_data_channels[image_indices[batch_indices]].reshape(-1, 1, 200, 200)\n",
        "            arr = np.concatenate([image_batch, measure_data_channel_batch], axis=1)\n",
        "            sequence_batch = subsequences[batch_indices]\n",
        "            arr = torch.Tensor(arr).type(torch.float).to(device)\n",
        "            seq1 = torch.Tensor(sequence_batch[:, :-1]).type(torch.long).to(device)\n",
        "            seq2 = torch.Tensor(sequence_batch[:, 1:]).type(torch.long).to(device)\n",
        "            out, _, _ = self.forward(arr, seq1)\n",
        "            out = out.view(-1, len_lexicon)\n",
        "            targets = seq2.view(-1)\n",
        "            loss = loss_fn(out, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            if i % print_every == 0:\n",
        "                n = np.random.randint(len(subsequences))\n",
        "                image_index = image_indices[n]\n",
        "                image = images[image_index].reshape(1, 1, 200, 200)/255\n",
        "                measure_data_channel = measure_data_channels[image_index].reshape(1, 1, 200, 200)\n",
        "                arr = np.concatenate([image, measure_data_channel], axis=1)\n",
        "                arr = torch.Tensor(arr).type(torch.float).to(device)\n",
        "                pc = other_data['aux_data'][image_index]['pc']\n",
        "                pc = ' '.join([ix_to_word[str(ix)] for ix in pc])\n",
        "                pred_seq = self.predict(arr)\n",
        "                pred_seq = ' '.join(pred_seq)\n",
        "                with open('./log_preprocessed_model-2019-09-23.txt', 'a+') as f:\n",
        "                    info_string = f\"\"\"\n",
        "                    ----\n",
        "                    iteration: {i}\n",
        "                    time elapsed: {time.time() - train_start_time}\n",
        "                    loss: {loss}\n",
        "                    ----\n",
        "                    pred: {pred_seq}\n",
        "                    ----\n",
        "                    true: {pc}\n",
        "                    ----\n",
        "\n",
        "\n",
        "\n",
        "                    \"\"\".replace('    ', '')\n",
        "                    print(info_string)\n",
        "                    f.write(info_string)\n",
        "            if i % 5000 == 0 and i != 0:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] *= rate_decay\n",
        "                torch.save(self, f'./preprocessed_model_checkpoint_iteration_{i}-2019-09-23.pt')\n",
        "            \n",
        "             \n",
        "    def predict(self, arr):\n",
        "        self.eval()    \n",
        "        with torch.no_grad():\n",
        "            arr = arr.view(1,2, 200, 200)\n",
        "            output_sequence = ['<START>']\n",
        "            h1 = torch.zeros(2, 1, self.lstm_hidden_size).to(device)\n",
        "            c1 = torch.zeros(2, 1, self.lstm_hidden_size).to(device)\n",
        "            h2 = torch.zeros(2, 1, self.lstm_hidden_size).to(device)\n",
        "            c2 = torch.zeros(2, 1, self.lstm_hidden_size).to(device)\n",
        "            while output_sequence[-1] != '<END>' and len(output_sequence)<400:\n",
        "                language_input = torch.Tensor([word_to_ix[output_sequence[-1]]]).type(torch.long).view(1, 1).to(device)\n",
        "                out, (h1, c1), (h2, c2) = self.forward(arr, language_input, (h1, c1), (h2, c2))\n",
        "                _, language_input = out[0, 0, :].max(0)\n",
        "                output_sequence.append(ix_to_word[str(language_input.item())])\n",
        "        self.train()\n",
        "        return output_sequence\n",
        "\n",
        "    def predict_from_image(self, path, measure_length, key_number):\n",
        "        # path should be path to a png\n",
        "        image = io.imread(path)/255\n",
        "        # handle the conversion from rgb and rgba pngs\n",
        "        if len(image.shape) == 3:\n",
        "            if image.shape[2] == 3:\n",
        "                image = rgb2gray(image)\n",
        "            elif image.shape[3] == 4:\n",
        "                image = rgb2gray(image[:, :, :3])\n",
        "        image = transform.resize(image, (200, 200), cval=1)\n",
        "        measure_channel = get_measure_data_channel(measure_length, key_number, 200, 200)\n",
        "        arr = np.array([image, measure_channel])\n",
        "        arr = torch.Tensor(arr).type(torch.float).to(device)\n",
        "        return self.predict(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raR-KcfBzdls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net(len_lexicon, lstm_hidden_size, fc1_output_size, device).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_dJqFYbyE-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6766aeb-2bde-4355-b98f-7632669d44c4"
      },
      "source": [
        "model.fit(100, optimizer, loss_fn, 1, print_every=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----\n",
            "iteration: 0\n",
            "time elapsed: 1.1943106651306152\n",
            "loss: 3.4831182956695557\n",
            "----\n",
            "pred: <START> type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type\n",
            "----\n",
            "true: <START> measure note pitch B 0 4 } duration 4 } type quarter } staff 1 } } note pitch C 0 5 } duration 4 } type quarter } staff 1 } } note rest } duration 4 } type quarter } staff 1 } } note pitch E 0 5 } duration 4 } type quarter } staff 1 } } backup duration 16 } } note pitch D 0 3 } duration 4 } type quarter } staff 2 } } note rest } duration 4 } type quarter } staff 2 } } note pitch D 0 3 } duration 4 } type quarter } staff 2 } } note pitch D 0 3 } duration 4 } type quarter } staff 2 } } note chord } pitch F 1 2 } duration 4 } type quarter } staff 2 } } } <END>\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "----\n",
            "iteration: 10\n",
            "time elapsed: 3.7228047847747803\n",
            "loss: 3.4878764152526855\n",
            "----\n",
            "pred: <START> type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type\n",
            "----\n",
            "true: <START> measure note pitch A 0 4 } duration 4 } type quarter } staff 1 } } note chord } pitch F 0 5 } duration 4 } type quarter } staff 1 } } note pitch F 0 4 } duration 4 } type quarter } staff 1 } } note pitch B 1 4 } duration 4 } type quarter } staff 1 } } note pitch A 0 4 } duration 4 } type quarter } staff 1 } } backup duration 16 } } note pitch B -1 3 } duration 4 } type quarter } staff 2 } } note pitch F 0 4 } duration 4 } type quarter } staff 2 } } note pitch C 0 4 } duration 4 } type quarter } staff 2 } } note pitch D -1 4 } duration 4 } type quarter } staff 2 } } } <END>\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "----\n",
            "iteration: 20\n",
            "time elapsed: 6.275178909301758\n",
            "loss: 3.477480888366699\n",
            "----\n",
            "pred: <START> type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type\n",
            "----\n",
            "true: <START> measure note rest } duration 4 } type quarter } staff 1 } } note pitch B 0 5 } duration 4 } type quarter } staff 1 } } note rest } duration 4 } type quarter } staff 1 } } backup duration 12 } } note pitch E 1 4 } duration 4 } type quarter } staff 2 } } note pitch E 0 4 } duration 4 } type quarter } staff 2 } } note rest } duration 4 } type quarter } staff 2 } } } <END>\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "----\n",
            "iteration: 30\n",
            "time elapsed: 8.810072183609009\n",
            "loss: 3.471515417098999\n",
            "----\n",
            "pred: <START> type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type type\n",
            "----\n",
            "true: <START> measure note pitch A 0 4 } duration 4 } type quarter } staff 1 } } note pitch B 0 3 } duration 4 } type quarter } staff 1 } } note pitch G 0 3 } duration 4 } type quarter } staff 1 } } note pitch C -1 4 } duration 4 } type quarter } staff 1 } } backup duration 16 } } note rest } duration 4 } type quarter } staff 2 } } note rest } duration 4 } type quarter } staff 2 } } note pitch E 1 2 } duration 4 } type quarter } staff 2 } } note pitch B 1 2 } duration 4 } type quarter } staff 2 } } } <END>\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-26bac29c7488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-56ddfb9ba0be>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, total_iterations, optimizer, loss_fn, rate_decay, print_every)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aux_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mpred_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mpred_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./log_preprocessed_model-2019-09-23.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-56ddfb9ba0be>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, arr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<END>'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mlanguage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R7fFVBaz2zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}